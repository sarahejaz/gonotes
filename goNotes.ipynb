{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "goNotes.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "OEQ3R2aU1pmS"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "694fe5c971dd4a31a2dd00ff6b07486c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a59bc6ec571946588e73133e56a7af3b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ecb15f661c4343b484cb637968ea5cc8",
              "IPY_MODEL_ffbb57a985ef480cbacecc349f6143c9"
            ]
          }
        },
        "a59bc6ec571946588e73133e56a7af3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ecb15f661c4343b484cb637968ea5cc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4e626c578b51457a896532f40e7a81cc",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 291,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 291,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_eeb80750306a44ba833adc0947c505e8"
          }
        },
        "ffbb57a985ef480cbacecc349f6143c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bb03bff1a0364996a761d4202882eda2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 291/291 [00:00&lt;00:00, 809B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fdf8282142fb4aa4bf96dad138314cdf"
          }
        },
        "4e626c578b51457a896532f40e7a81cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "eeb80750306a44ba833adc0947c505e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bb03bff1a0364996a761d4202882eda2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fdf8282142fb4aa4bf96dad138314cdf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "00c9a96258c14029a6db410a392f6d1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_16f10ad441d345b3bdf76ce354c81cee",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e1573dfe794e4eb5beed7b1b3a72bb4f",
              "IPY_MODEL_38d1b514e64e4256a43dfe12d35174dd"
            ]
          }
        },
        "16f10ad441d345b3bdf76ce354c81cee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e1573dfe794e4eb5beed7b1b3a72bb4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a621adac19e94da5803c493b53894966",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 163,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 163,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6236cf0ff71e4b4cb74f1ff58add8ab8"
          }
        },
        "38d1b514e64e4256a43dfe12d35174dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6080e19a99cd4109a4382f13f7c0b013",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 163/163 [00:01&lt;00:00, 141B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1ebe3e73b88548c2b3f2a23761ab4468"
          }
        },
        "a621adac19e94da5803c493b53894966": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6236cf0ff71e4b4cb74f1ff58add8ab8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6080e19a99cd4109a4382f13f7c0b013": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1ebe3e73b88548c2b3f2a23761ab4468": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "01b0a4f460104fb18ec2fa6d21ee0576": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_16c64aa4534b4a2caac30a4e307d9346",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4d0c5e071f8d4c619bf273085a1c06f1",
              "IPY_MODEL_69e928d8c8324438a93940328dc4f222"
            ]
          }
        },
        "16c64aa4534b4a2caac30a4e307d9346": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4d0c5e071f8d4c619bf273085a1c06f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e2324cd1d3974f129c149ddb0a38775f",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 85,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 85,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cb2f024cc4bf433fbffd560ab45471e3"
          }
        },
        "69e928d8c8324438a93940328dc4f222": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_66a8060fd3be4e31ae2360faeaf3e002",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 85.0/85.0 [00:00&lt;00:00, 172B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_66a8fa9ee93342bf8beb8efd4443ea57"
          }
        },
        "e2324cd1d3974f129c149ddb0a38775f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cb2f024cc4bf433fbffd560ab45471e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "66a8060fd3be4e31ae2360faeaf3e002": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "66a8fa9ee93342bf8beb8efd4443ea57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "77a4860d17854754b4b60e90af458e55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fc0b1bd68df444a1b3342465ef5d7bbc",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b56f82af91214afc90b10e95ef5e684f",
              "IPY_MODEL_dbf9e59818cb44448a1ee61fa6c3e068"
            ]
          }
        },
        "fc0b1bd68df444a1b3342465ef5d7bbc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b56f82af91214afc90b10e95ef5e684f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4e5534914d81470d825ae7470394ef59",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 843,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 843,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a41422b7b8a84ac3875c94bb9fa1e81a"
          }
        },
        "dbf9e59818cb44448a1ee61fa6c3e068": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bcb95e3f73bb4604a5b0a399004fe6f6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 843/843 [00:01&lt;00:00, 439B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5404c91def1c430282c2ce5cf1fde70e"
          }
        },
        "4e5534914d81470d825ae7470394ef59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a41422b7b8a84ac3875c94bb9fa1e81a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bcb95e3f73bb4604a5b0a399004fe6f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5404c91def1c430282c2ce5cf1fde70e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "67e9d31d64a940e6a9131a73d1e0ae65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2f4ab3c4b51c4b5f98514b7e66e02fe4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_09dd2ed640c141ebb21f30f5d6c4acb8",
              "IPY_MODEL_a8a2d3ac3a2a4c5bb18afa8f1822f76c"
            ]
          }
        },
        "2f4ab3c4b51c4b5f98514b7e66e02fe4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "09dd2ed640c141ebb21f30f5d6c4acb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b525b90b191a49d2ab259bfb94ab194f",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 377667514,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 377667514,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2c712871007e4859a65083313fcad297"
          }
        },
        "a8a2d3ac3a2a4c5bb18afa8f1822f76c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_81104ef35a734113bd73b1ce994a7745",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 378M/378M [00:08&lt;00:00, 45.3MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4cae64b8df9c4fd6b5d99db8dd98434a"
          }
        },
        "b525b90b191a49d2ab259bfb94ab194f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2c712871007e4859a65083313fcad297": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "81104ef35a734113bd73b1ce994a7745": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4cae64b8df9c4fd6b5d99db8dd98434a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sarahejaz/gonotes/blob/main/goNotes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zj613EFHxtB"
      },
      "source": [
        "#Mounting the Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7y9-uXb3ZJD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "528af0af-877f-4a51-dd58-e689ec884dec"
      },
      "source": [
        "  from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vnRhRUP69c8"
      },
      "source": [
        "#Installations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylJDJCDO66AJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ebc8239-6f81-4a80-a68e-3d6187b213f4"
      },
      "source": [
        "!pip install -q youtube-dl"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.9MB 9.5MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQ5nRr8H7Hjj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31953859-db0b-49fb-c8bc-3897af9bd4e9"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/b2/57495b5309f09fa501866e225c84532d1fd89536ea62406b2181933fb418/transformers-4.5.1-py3-none-any.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 8.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 43.2MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 32.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.45 tokenizers-0.10.2 transformers-4.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkH6CMd07Ji5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de8c765b-40e2-411b-b639-21907e5a1df6"
      },
      "source": [
        "!pip install pydub"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pydub\n",
            "  Downloading https://files.pythonhosted.org/packages/a6/53/d78dc063216e62fc55f6b2eebb447f6a4b0a59f55c8406376f76bf959b08/pydub-0.25.1-py2.py3-none-any.whl\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TO00bhQw7M_4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf06aa95-a965-4b21-fff1-2174ed085e6e"
      },
      "source": [
        "!pip install punctuator"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting punctuator\n",
            "  Downloading https://files.pythonhosted.org/packages/99/0f/180596123582315cb72c805c605b0ab20942b3035725fca0525729474a7d/punctuator-0.9.6.tar.gz\n",
            "Collecting nltk>=3.4.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/37/9532ddd4b1bbb619333d5708aaad9bf1742f051a664c3c6fa6632a105fd8/nltk-3.6.2-py3-none-any.whl (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 9.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from punctuator) (1.19.5)\n",
            "Requirement already satisfied: theano>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from punctuator) (1.0.5)\n",
            "Collecting gdown>=3.8.3\n",
            "  Downloading https://files.pythonhosted.org/packages/50/21/92c3cfe56f5c0647145c4b0083d0733dd4890a057eb100a8eeddf949ffe9/gdown-3.12.2.tar.gz\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk>=3.4.5->punctuator) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk>=3.4.5->punctuator) (1.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk>=3.4.5->punctuator) (4.41.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from nltk>=3.4.5->punctuator) (2019.12.20)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from theano>=1.0.4->punctuator) (1.15.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from theano>=1.0.4->punctuator) (1.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown>=3.8.3->punctuator) (3.0.12)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown>=3.8.3->punctuator) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown>=3.8.3->punctuator) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown>=3.8.3->punctuator) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown>=3.8.3->punctuator) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown>=3.8.3->punctuator) (3.0.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown>=3.8.3->punctuator) (1.7.1)\n",
            "Building wheels for collected packages: gdown\n",
            "  Building wheel for gdown (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gdown: filename=gdown-3.12.2-cp37-none-any.whl size=9693 sha256=6ec1b3c452709bdd279bb13291605a5c9ac13409107bb16bcb48e2cfa1855552\n",
            "  Stored in directory: /root/.cache/pip/wheels/81/d0/d7/d9983facc6f2775411803e0e2d30ebf98efbf2fc6e57701e09\n",
            "Successfully built gdown\n",
            "Building wheels for collected packages: punctuator\n",
            "  Building wheel for punctuator (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for punctuator: filename=punctuator-0.9.6-cp37-none-any.whl size=25154 sha256=35e1c5d663ed570df9f58edb51068f448395efc2a29b49713b5753acd65ee62d\n",
            "  Stored in directory: /root/.cache/pip/wheels/9a/4b/83/024d41a639f2945705721ebc0b9c596880d492a487925f941a\n",
            "Successfully built punctuator\n",
            "Installing collected packages: nltk, gdown, punctuator\n",
            "  Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "  Found existing installation: gdown 3.6.4\n",
            "    Uninstalling gdown-3.6.4:\n",
            "      Successfully uninstalled gdown-3.6.4\n",
            "Successfully installed gdown-3.12.2 nltk-3.6.2 punctuator-0.9.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6yy3JZQ8KDT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0c5e110-b5f6-4c3a-c8be-30c4e0bd87a9"
      },
      "source": [
        "!pip install gdown"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (3.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown) (3.0.12)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown) (4.41.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.24.3)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIrP8w278ssb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01cb4156-ee56-4cf8-e0c0-85eb68506cd7"
      },
      "source": [
        "!pip install autocorrect"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting autocorrect\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/31/aa5d4b54baafed2d0eef47e30d527ea60eb7357f11c3b5adc58262a3c693/autocorrect-2.5.0.tar.gz (622kB)\n",
            "\u001b[K     |████████████████████████████████| 624kB 9.5MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: autocorrect\n",
            "  Building wheel for autocorrect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for autocorrect: filename=autocorrect-2.5.0-cp37-none-any.whl size=621854 sha256=a5748dbb9ea9ddd8e9b2c6c8f6f9f603c8b983f020381244b07102209085aeb4\n",
            "  Stored in directory: /root/.cache/pip/wheels/1f/71/da/4a15028d25fbd5fb97fb76c5f76f0ad86f0caa69394dd7cfa7\n",
            "Successfully built autocorrect\n",
            "Installing collected packages: autocorrect\n",
            "Successfully installed autocorrect-2.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9YXihAR9NIJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4aaa00d0-3f40-4c98-cb74-b06ecd35833e"
      },
      "source": [
        "!pip install gensim"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.19.5)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.0.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8b6cZ2-9qad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5baf26df-7d0c-408a-8bae-fa20a110df21"
      },
      "source": [
        "!pip install crepe"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting crepe\n",
            "  Downloading https://files.pythonhosted.org/packages/c8/74/1677b9369f233745b3dedf707ce26fb935c5c400379c45400df818f3a805/crepe-0.0.11.tar.gz\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from crepe) (1.19.5)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from crepe) (1.4.1)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from crepe) (3.2.2)\n",
            "Requirement already satisfied: resampy<0.3.0,>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from crepe) (0.2.2)\n",
            "Requirement already satisfied: h5py<3.0.0,>=2.7.0 in /usr/local/lib/python3.7/dist-packages (from crepe) (2.10.0)\n",
            "Collecting hmmlearn<0.3.0,>=0.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4b/98/a2829aeb942b7146034d497afb3fc738a78a4fbd4797a039c19a94bb31f7/hmmlearn-0.2.5-cp37-cp37m-manylinux1_x86_64.whl (369kB)\n",
            "\u001b[K     |████████████████████████████████| 378kB 11.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from crepe) (2.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.16 in /usr/local/lib/python3.7/dist-packages (from crepe) (0.22.2.post1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->crepe) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->crepe) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->crepe) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->crepe) (2.4.7)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.7/dist-packages (from resampy<0.3.0,>=0.2.0->crepe) (1.15.0)\n",
            "Requirement already satisfied: numba>=0.32 in /usr/local/lib/python3.7/dist-packages (from resampy<0.3.0,>=0.2.0->crepe) (0.51.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from imageio>=2.3.0->crepe) (7.1.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.16->crepe) (1.0.1)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.32->resampy<0.3.0,>=0.2.0->crepe) (0.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.32->resampy<0.3.0,>=0.2.0->crepe) (54.2.0)\n",
            "Building wheels for collected packages: crepe\n",
            "  Building wheel for crepe (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for crepe: filename=crepe-0.0.11-cp37-none-any.whl size=134848476 sha256=6955d8e2e97d20f32c9c4c16b881d6e7404313eb400139a068b4023b8575c972\n",
            "  Stored in directory: /root/.cache/pip/wheels/7f/68/d0/502d27bfe590bfa51c6fe95cf9e4482fed18c22c480a8d7c77\n",
            "Successfully built crepe\n",
            "Installing collected packages: hmmlearn, crepe\n",
            "Successfully installed crepe-0.0.11 hmmlearn-0.2.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L12rW0o-WEFc",
        "outputId": "08e644db-1396-4596-daa7-ef96e803f729"
      },
      "source": [
        "!pip install fuzzywuzzy[speedup]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fuzzywuzzy[speedup]\n",
            "  Downloading https://files.pythonhosted.org/packages/43/ff/74f23998ad2f93b945c0309f825be92e04e0348e062026998b5eefef4c33/fuzzywuzzy-0.18.0-py2.py3-none-any.whl\n",
            "Collecting python-levenshtein>=0.12; extra == \"speedup\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2a/dc/97f2b63ef0fa1fd78dcb7195aca577804f6b2b51e712516cc0e902a9a201/python-Levenshtein-0.12.2.tar.gz (50kB)\n",
            "\r\u001b[K     |██████▌                         | 10kB 13.9MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 20kB 18.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 30kB 18.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 40kB 12.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 4.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from python-levenshtein>=0.12; extra == \"speedup\"->fuzzywuzzy[speedup]) (54.2.0)\n",
            "Building wheels for collected packages: python-levenshtein\n",
            "  Building wheel for python-levenshtein (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-levenshtein: filename=python_Levenshtein-0.12.2-cp37-cp37m-linux_x86_64.whl size=149797 sha256=3561d0e9a2a47c1aa18dce13cd4493556841b4d6a6d9bc71ffa878131a1c1a38\n",
            "  Stored in directory: /root/.cache/pip/wheels/b3/26/73/4b48503bac73f01cf18e52cd250947049a7f339e940c5df8fc\n",
            "Successfully built python-levenshtein\n",
            "Installing collected packages: python-levenshtein, fuzzywuzzy\n",
            "Successfully installed fuzzywuzzy-0.18.0 python-levenshtein-0.12.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DsUE36HX7Tiz"
      },
      "source": [
        "#Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xn8eGVa17TMr"
      },
      "source": [
        "import os\n",
        "from os.path import exists, join, basename, splitext\n",
        "from pydub import AudioSegment\n",
        "from pydub.silence import split_on_silence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6voZZDxY7yua"
      },
      "source": [
        "import torch\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvuYIphQ8Csp"
      },
      "source": [
        "import librosa\n",
        "import torch\n",
        "from transformers import Wav2Vec2ForCTC, Wav2Vec2Tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651,
          "referenced_widgets": [
            "694fe5c971dd4a31a2dd00ff6b07486c",
            "a59bc6ec571946588e73133e56a7af3b",
            "ecb15f661c4343b484cb637968ea5cc8",
            "ffbb57a985ef480cbacecc349f6143c9",
            "4e626c578b51457a896532f40e7a81cc",
            "eeb80750306a44ba833adc0947c505e8",
            "bb03bff1a0364996a761d4202882eda2",
            "fdf8282142fb4aa4bf96dad138314cdf",
            "00c9a96258c14029a6db410a392f6d1b",
            "16f10ad441d345b3bdf76ce354c81cee",
            "e1573dfe794e4eb5beed7b1b3a72bb4f",
            "38d1b514e64e4256a43dfe12d35174dd",
            "a621adac19e94da5803c493b53894966",
            "6236cf0ff71e4b4cb74f1ff58add8ab8",
            "6080e19a99cd4109a4382f13f7c0b013",
            "1ebe3e73b88548c2b3f2a23761ab4468",
            "01b0a4f460104fb18ec2fa6d21ee0576",
            "16c64aa4534b4a2caac30a4e307d9346",
            "4d0c5e071f8d4c619bf273085a1c06f1",
            "69e928d8c8324438a93940328dc4f222",
            "e2324cd1d3974f129c149ddb0a38775f",
            "cb2f024cc4bf433fbffd560ab45471e3",
            "66a8060fd3be4e31ae2360faeaf3e002",
            "66a8fa9ee93342bf8beb8efd4443ea57",
            "77a4860d17854754b4b60e90af458e55",
            "fc0b1bd68df444a1b3342465ef5d7bbc",
            "b56f82af91214afc90b10e95ef5e684f",
            "dbf9e59818cb44448a1ee61fa6c3e068",
            "4e5534914d81470d825ae7470394ef59",
            "a41422b7b8a84ac3875c94bb9fa1e81a",
            "bcb95e3f73bb4604a5b0a399004fe6f6",
            "5404c91def1c430282c2ce5cf1fde70e",
            "67e9d31d64a940e6a9131a73d1e0ae65",
            "2f4ab3c4b51c4b5f98514b7e66e02fe4",
            "09dd2ed640c141ebb21f30f5d6c4acb8",
            "a8a2d3ac3a2a4c5bb18afa8f1822f76c",
            "b525b90b191a49d2ab259bfb94ab194f",
            "2c712871007e4859a65083313fcad297",
            "81104ef35a734113bd73b1ce994a7745",
            "4cae64b8df9c4fd6b5d99db8dd98434a"
          ]
        },
        "id": "OA5gFVptoViN",
        "outputId": "a592343d-a3b5-4012-8862-c8a210949e81"
      },
      "source": [
        "tokenizer = Wav2Vec2Tokenizer.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
        "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\").to(\"cuda\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "694fe5c971dd4a31a2dd00ff6b07486c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=291.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "00c9a96258c14029a6db410a392f6d1b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=163.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "01b0a4f460104fb18ec2fa6d21ee0576",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=85.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/models/wav2vec2/tokenization_wav2vec2.py:358: FutureWarning: The class `Wav2Vec2Tokenizer` is deprecated and will be removed in version 5 of Transformers. Please use `Wav2Vec2Processor` or `Wav2Vec2CTCTokenizer` instead.\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "77a4860d17854754b4b60e90af458e55",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=843.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "67e9d31d64a940e6a9131a73d1e0ae65",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=377667514.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-086042abae1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWav2Vec2Tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"facebook/wav2vec2-base-960h\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWav2Vec2ForCTC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"facebook/wav2vec2-base-960h\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    671\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m     def register_backward_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    407\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    669\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m    670\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m--> 671\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;31m# This function throws if there's a driver initialization error, no GPUs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;31m# are found or any other error occurs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: No CUDA GPUs are available"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2XWQtSN8PbY"
      },
      "source": [
        "import gdown"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nVGFm_a_3Ls"
      },
      "source": [
        "''' -*- importing gdown to download the Demo Europarl model -*- '''\n",
        "\n",
        "url = 'https://drive.google.com/uc?id=0B7BsN5f2F1fZd1Q0aXlrUDhDbnM'\n",
        "output = 'Demo-Europarl-EN.pcl'\n",
        "gdown.download(url, output, quiet=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHXG6eZ08at9"
      },
      "source": [
        "from punctuator import Punctuator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqF9pdib8f9s"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWN2j7Y08nWS"
      },
      "source": [
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "wordnet_lemmatizer = WordNetLemmatizer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EUS4VRF8y1V"
      },
      "source": [
        "from autocorrect import Speller"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8DOst2m85He"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer \n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7gFQphz8_T_"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEkYTNRS9H2U"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DiyYXrf9UMw"
      },
      "source": [
        "from gensim.summarization import keywords"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NasVxZfl9aKC"
      },
      "source": [
        "from gensim.summarization import summarize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6Oy7HIS9hg-"
      },
      "source": [
        "from pydub.utils import make_chunks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XiFkn4eX_Uup"
      },
      "source": [
        "import crepe\n",
        "import pandas as pd\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqKGHXGoWNzj"
      },
      "source": [
        "from fuzzywuzzy import fuzz\n",
        "from fuzzywuzzy import process"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vI2rFRDe8RXk"
      },
      "source": [
        "#Creating Files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wm7kfsvL-Uek"
      },
      "source": [
        "def creating_files():\n",
        "  inference_file = open(\"inference.txt\",\"w+\")\n",
        "  inference_file.truncate(0)\n",
        "  inference_file.close()\n",
        "  punctuated_file = open(\"PunctuatedText.txt\",\"w+\")\n",
        "  punctuated_file.truncate(0)\n",
        "  punctuated_file.close()\n",
        "  summarized_file = open(\"SummarizedText.txt\",\"w+\")\n",
        "  summarized_file.truncate(0)\n",
        "  summarized_file.close()\n",
        "  lemmatized_file = open(\"LemmatizedText.txt\",\"w+\")\n",
        "  lemmatized_file.truncate(0)\n",
        "  lemmatized_file.close()\n",
        "  final_infer_file = open(\"finalInference.txt\",\"w+\")\n",
        "  final_infer_file.truncate(0)\n",
        "  final_infer_file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9LjACB42bAo"
      },
      "source": [
        "''' -*- testing YouTube Display  -*- '''\n",
        "# from IPython.display import YouTubeVideo\n",
        "#networking lecture id='2xbAiKyTveU'\n",
        "\n",
        "#machine lecture id='HcqpanDadyQ'\n",
        "# YouTubeVideo(YOUTUBE_ID)\n",
        "\n",
        "# YOUTUBE_ID=\"\"\n",
        "# def setYoutubeID(ID):\n",
        "#   YOUTUBE_ID = ID"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6N0gUez9fBv"
      },
      "source": [
        "#Downloading the Audio from Youtube Video"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WO8vmrUP2xN9"
      },
      "source": [
        "''' -*- executing Deep Speech Model -*- '''\n",
        "def dowloadAudio(YOUTUBE_ID):\n",
        "  !youtube-dl --extract-audio --audio-format wav --output \"YoutubeVid.%(ext)s\" https://www.youtube.com/watch\\?v\\={YOUTUBE_ID}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VvcVBMKl2n0"
      },
      "source": [
        "#Chunking the Youtube Audio on the basis of silence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W64hy0oOHjp_"
      },
      "source": [
        "def chunk_on_silence():\n",
        "  if not exists(\"YoutubeVidChunks\"):\n",
        "    os.mkdir(\"YoutubeVidChunks\")\n",
        "  sound_file = AudioSegment.from_wav(\"YoutubeVid.wav\")\n",
        "  audio_chunks = split_on_silence(sound_file, min_silence_len=2000, silence_thresh=-40, keep_silence=1000 )\n",
        "  for i, chunk in enumerate(audio_chunks):\n",
        "    out_file = \"YoutubeVidChunks/chunk{0}.wav\".format(i)\n",
        "    chunk.export(out_file, format=\"wav\")\n",
        "  return audio_chunks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VpHkB2Ifnxz"
      },
      "source": [
        "#Huggingface wav2vec2:\n",
        "https://www.analyticsvidhya.com/blog/2021/02/hugging-face-introduces-the-first-automatic-speech-recognition-model-wav2vec2/\n",
        "https://huggingface.co/facebook/wav2vec2-base-960h?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vREa4KaV-_LV"
      },
      "source": [
        "#load model and tokenizer\n",
        "def wav2vec2(audio_chunks):\n",
        "  print(\"\\n\")\n",
        "  for i, chunk in enumerate(audio_chunks):\n",
        "    out_file = \"YoutubeVidChunks/chunk{0}.wav\".format(i)\n",
        "    speech, rate = librosa.load(out_file,sr=16000)\n",
        "    input_values = tokenizer(speech, return_tensors = 'pt').input_values\n",
        "    with torch.no_grad():\n",
        "            logits = model(input_values.to(\"cuda\")).logits\n",
        "    #Store predicted id's\n",
        "    predicted_ids = torch.argmax(logits, dim =-1)\n",
        "\n",
        "    #decode the audio to generate text\n",
        "    transcriptions = tokenizer.decode(predicted_ids[0]).lower()\n",
        "    with open('inference.txt', 'a+') as writefile:\n",
        "      writefile.write(transcriptions+\" \")\n",
        "  print(transcriptions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcXibLAqJdL6"
      },
      "source": [
        "#Pip Punctuator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8VSMxsaJiR9"
      },
      "source": [
        "Reference: https://pypi.org/project/punctuator/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8o7sUaPt0Yd"
      },
      "source": [
        "''' -*- punctuating the raw text output from Deep Speech using Pip Punctuator -*- '''\n",
        "\n",
        "def Punctuate():\n",
        "  f = open('inference.txt', \"r\")\n",
        "  lines = f.readline()\n",
        "  f.close()\n",
        "  p = Punctuator('Demo-Europarl-EN.pcl')\n",
        "  punctLines=p.punctuate(lines)\n",
        "  print(punctLines)\n",
        "  with open('PunctuatedText.txt', 'w+') as writefile:\n",
        "    writefile.write(punctLines)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "il_IhagEmIyV"
      },
      "source": [
        "Auto-correcting the Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKWvaiA80IVM"
      },
      "source": [
        "def AutoCorrection():\n",
        "  f = open('PunctuatedText.txt', \"r\")\n",
        "  lines = f.readline()\n",
        "  f.close()\n",
        "  spell = Speller()\n",
        "  correct_spell=spell(lines)\n",
        "  print(correct_spell)\n",
        "  lines_list = nltk.tokenize.sent_tokenize(correct_spell)\n",
        "  with open('finalInference.txt', 'w+') as writefile:\n",
        "    writefile.write(correct_spell)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lP9oH399LxhE"
      },
      "source": [
        "#NLTK Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5AayV4HiMEvU"
      },
      "source": [
        "Reference: https://www.datacamp.com/community/tutorials/stemming-lemmatization-python"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jt8nmx4qTO_"
      },
      "source": [
        "''' -*- Function for word tokenization and lemmatization -*- '''\n",
        "\n",
        "def lemmSentence(sentence):\n",
        "    token_words=word_tokenize(sentence)\n",
        "    token_words\n",
        "    lemm_sentence=[]\n",
        "    for word in token_words:\n",
        "        lemm_sentence.append(wordnet_lemmatizer.lemmatize(word))\n",
        "        lemm_sentence.append(\" \")\n",
        "    return \"\".join(lemm_sentence)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TttxnPa_Wly"
      },
      "source": [
        "def lemmatizedText():\n",
        "  lemm_file= open(\"LemmatizedText.txt\",\"w+\")\n",
        "  sentences=\"\"\n",
        "  f = open('finalInference.txt', \"r\")\n",
        "  lines = f.readline()\n",
        "  f.close()\n",
        "  lines_list = nltk.tokenize.sent_tokenize(lines)\n",
        "  for line in lines_list:\n",
        "      lemm_sentence=lemmSentence(line)\n",
        "      lemm_file.write(lemm_sentence)\n",
        "      sentences+=lemm_sentence\n",
        "  lemm_file.close()\n",
        "  return sentences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LvU35FYMS6K"
      },
      "source": [
        "#Count Vectorizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFiAw4UfMV19"
      },
      "source": [
        "Reference: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCC75JRvmWd6"
      },
      "source": [
        "#Extracting keywords and key sentences using Gensim"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edwbqajy2MPj"
      },
      "source": [
        "def extract_keywords():\n",
        "  f = open('LemmatizedText.txt', \"r\")\n",
        "  sentences = f.readline()\n",
        "  f.close()\n",
        "  key_terms=keywords(sentences,words=23)\n",
        "  print(key_terms)\n",
        "  keywords_list=key_terms.split()\n",
        "  topic_word=keywords_list[0]\n",
        "  print(\"Topic Word\",topic_word)\n",
        "  return key_terms, keywords_list, topic_word"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyiQTtL2A7mp"
      },
      "source": [
        "def extract_nouns(key_terms):\n",
        "  is_noun = lambda pos: pos[:2] == 'NN'\n",
        "  # do the nlp stuff\n",
        "  tokenized = nltk.word_tokenize(key_terms)\n",
        "  keyword_nouns = [word for (word, pos) in nltk.pos_tag(tokenized) if is_noun(pos)] \n",
        "  print(keyword_nouns)\n",
        "  return keyword_nouns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0ofL6scmlhw"
      },
      "source": [
        "def summarize_text():\n",
        "  f = open('finalInference.txt', \"r\")\n",
        "  sentences = f.readline()\n",
        "  f.close()\n",
        "  summarized_text=summarize(sentences,ratio=0.3)\n",
        "  print(summarized_text)\n",
        "  with open('SummarizedText.txt', 'w+') as writefile:\n",
        "    writefile.write(summarized_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adm7YUlmSFKB"
      },
      "source": [
        "# with open('SummarizedText.txt') as f:\n",
        "#     Summarized_lines = f.readlines()\n",
        "# with open('finalInference.txt') as f:\n",
        "#     Inferenced_lines = f.readlines()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEQ3R2aU1pmS"
      },
      "source": [
        "#ROUGE EVALUATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iKLq5Pqhli1"
      },
      "source": [
        "# !pip install git+https://github.com/tagucci/pythonrouge.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5x0YpD9ls1Ad"
      },
      "source": [
        "# !apt-get install -y cpanminus\n",
        "\n",
        "# !cpanm --force XML::Parser"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5X_s8Wxhnm_"
      },
      "source": [
        "# from pythonrouge.pythonrouge import Pythonrouge\n",
        "\n",
        " \n",
        "\n",
        "# # system summary(prediction) & reference summary\n",
        "# summary = [[Summarized_lines]]\n",
        "\n",
        "# reference = [[[Inferenced_lines]]]\n",
        "\n",
        "# # initialize setting of ROUGE to evaluate ROUGE-1, 2, W and SU4\n",
        "\n",
        "# rouge = Pythonrouge(summary_file_exist=False,\n",
        "\n",
        "#                     summary=summary, reference=reference,\n",
        "\n",
        "#                     n_gram=2, ROUGE_SU4=True, ROUGE_L=True,ROUGE_W=True,ROUGE_W_Weight=1.2,\n",
        "\n",
        "#                     recall_only=False, stemming=True, stopwords=True,\n",
        "\n",
        "#                     word_level=True, length_limit=True, length=50,\n",
        "\n",
        "#                     use_cf=False, cf=95, scoring_formula='average',\n",
        "\n",
        "#                     resampling=True, samples=1000, favor=True, p=0.5)\n",
        "\n",
        "# score = rouge.calc_score()\n",
        "\n",
        "# print(score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0RakBVYj-Hw"
      },
      "source": [
        "# rouge=list(score.keys())\n",
        "# r_score=list(score.values())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTWQltraka54"
      },
      "source": [
        "# print(rouge)\n",
        "# print(r_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-XMTNyF_Nnq"
      },
      "source": [
        "\n",
        "# rouge_12=rouge[0:6]\n",
        "# rscore_12=r_score[0:6]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5EoFRJl5p5l"
      },
      "source": [
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "# fig = plt.figure(figsize = (10, 5))\n",
        " \n",
        "# # ROUGE-1\n",
        "# plt.bar(rouge_12, rscore_12, color ='maroon')\n",
        "\n",
        "# plt.xlabel(\"ROUGE-1,2 Precision, Recall and F-Score\")\n",
        "# plt.ylabel(\"ROUGE-1,2 Scores\")\n",
        "# plt.title(\"ROUGE-1,2\")\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kl1O-Uh4_T3O"
      },
      "source": [
        "# rouge_LWS=rouge[6:15]\n",
        "# rscore_LWS=r_score[6:15]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mHRHVch8cxb"
      },
      "source": [
        "\n",
        "# fig = plt.figure(figsize = (15, 5))\n",
        "# # ROUGE-2\n",
        "# plt.bar(rouge_LWS, rscore_LWS, color ='blue')\n",
        "\n",
        "# plt.xlabel(\"ROUGE-LSW Precision, Recall and F-Score\")\n",
        "# plt.ylabel(\"ROUGE-LSW Scores\")\n",
        "# plt.title(\"ROUGE-LSW\")\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-t5K8i0gkawI"
      },
      "source": [
        "# rouge_1=rouge[0:3]\n",
        "# rouge_2=rouge[3:6]\n",
        "# rouge_L=rouge[6:9]\n",
        "# rouge_W=rouge[9:12]\n",
        "# rouge_SU=rouge[12:15]\n",
        "# rscore_1=r_score[0:3]\n",
        "# rscore_2=r_score[3:6]\n",
        "# rscore_L=r_score[6:9]\n",
        "# rscore_W=r_score[9:12]\n",
        "# rscore_SU=r_score[12:15]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bSf5RvwBAYu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Z8ygvGyApJm"
      },
      "source": [
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "# fig = plt.subplots(figsize =(10, 5))\n",
        "# # ROUGE-1\n",
        "# barWidth=0.5\n",
        "# plt.bar(rouge_1, rscore_1, color ='maroon', width = barWidth,\n",
        "#         edgecolor ='grey', label ='ROUGE-1')\n",
        "# plt.bar(rouge_2, rscore_2, color ='blue', width = barWidth,\n",
        "#         edgecolor ='grey', label ='ROUGE-2')\n",
        "\n",
        "# plt.xlabel(\"ROUGE-1,2 Precision, Recall and F-Score\")\n",
        "# plt.ylabel(\"ROUGE-1,2 Scores\")\n",
        "# plt.title(\"ROUGE-1,2\")\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7F3gCWoZt84q"
      },
      "source": [
        "# print(rouge_1,rouge_2,rouge_L,rouge_W,rouge_SU)\n",
        "# print(rscore_1,rscore_2,rscore_L,rscore_W,rscore_SU)\n",
        "# print(rouge_LWS,rouge_12)\n",
        "# print(rscore_12)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEMLdXlL8eTP"
      },
      "source": [
        "\n",
        "# fig = plt.figure(figsize = (5, 3))\n",
        "# # ROUGE-2\n",
        "# plt.bar(rouge_2, rscore_2, color ='blue',\n",
        "#         width = 0.4)\n",
        "\n",
        "# plt.xlabel(\"ROUGE-2 Precision, Recall and F-Score\")\n",
        "# plt.ylabel(\"ROUGE-2 Scores\")\n",
        "# plt.title(\"ROUGE-2\")\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZBHW7t7SOL9"
      },
      "source": [
        "#Split audio into 5 secs chunks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHQuh3DLR-on"
      },
      "source": [
        "def Chunks_five_sec():\n",
        "  if not exists(\"AudioChunks\"):\n",
        "    os.mkdir(\"AudioChunks\")\n",
        "  chunk_length_ms = 5000 # pydub calculates in millisec\n",
        "  sound_file = AudioSegment.from_wav(\"YoutubeVid.wav\")\n",
        "  chunks = make_chunks(sound_file, chunk_length_ms)\n",
        "  for i, chunk in enumerate(chunks):\n",
        "      chunk_name = \"AudioChunks/chunk{0}.wav\".format(i)\n",
        "      print (\"exporting\", chunk_name)\n",
        "      chunk.export(chunk_name, format=\"wav\")\n",
        "  return chunks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8M7UNf2yCUVh"
      },
      "source": [
        "#Search Key words in Audio "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoBniov6aiqm"
      },
      "source": [
        "def search_keywords(transcription, word_array):\n",
        "    i=0\n",
        "    flag=False\n",
        "    while(i<len(word_array)):\n",
        "      # print(\"index\",i)\n",
        "      if(word_array[i] in transcription):\n",
        "        print(transcription)\n",
        "        print(word_array[i])\n",
        "        word_array.remove(word_array[i])\n",
        "        flag=True\n",
        "      i+=1\n",
        "    if flag:\n",
        "      return True\n",
        "    return False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aqe82qSiYbfZ"
      },
      "source": [
        "def find_keywords_in_Audio(keyword_nouns,chunks):\n",
        "  words=keyword_nouns.copy()\n",
        "  print(words)\n",
        "  index_ids=[]\n",
        "  main_transcription=[]\n",
        "  for i, chunk in enumerate(chunks):\n",
        "    out_file = \"AudioChunks/chunk{0}.wav\".format(i)\n",
        "    speech, rate = librosa.load(out_file,sr=16000)\n",
        "    input_values = tokenizer(speech, return_tensors = 'pt').input_values\n",
        "    with torch.no_grad():\n",
        "            logits = model(input_values.to(\"cuda\")).logits\n",
        "    #Store predicted id's\n",
        "    predicted_ids = torch.argmax(logits, dim =-1)\n",
        "    #decode the audio to generate text\n",
        "    transcriptions = tokenizer.decode(predicted_ids[0]).lower()\n",
        "    spell = Speller()\n",
        "    transcriptions=spell(transcriptions)\n",
        "    main_transcription.append(transcriptions)\n",
        "    \n",
        "    if search_keywords(transcriptions, words):\n",
        "      index_ids.append(i)\n",
        "      #print(index_ids)\n",
        "  print(main_transcription)\n",
        "  print(index_ids)\n",
        "  return index_ids, main_transcription"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftThSHf2-7MC"
      },
      "source": [
        "#Crepe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXDl452A7YRX"
      },
      "source": [
        "\n",
        "def load_audio():\n",
        "  speech, rate = librosa.load(\"YoutubeVid.wav\",sr=16000)\n",
        "  return speech,rate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQQmpY6F7m77"
      },
      "source": [
        "def make_df_freq(speech,rate):\n",
        "  time, frequency, confidence, activation = crepe.predict(speech, rate, viterbi=True,step_size= 5000,center=False)\n",
        "  df = pd.DataFrame()\n",
        "  df = pd.DataFrame(columns=['time', 'frequency','confidence','activation'])\n",
        "  df['time']=time\n",
        "  df['frequency']=frequency\n",
        "  df['confidence']=confidence\n",
        "  df['activation']=activation\n",
        "  df\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sz-03nl1J_WJ"
      },
      "source": [
        "#Frequencies corresponding to keywords\n",
        "def extract_keywords_freq(df,index_ids):\n",
        "  time_Array=index_ids\n",
        "  freq_Array=[]\n",
        "  stepSize=5.0\n",
        "  for i in range(0,len(time_Array)):\n",
        "    row_index=time_Array[i]\n",
        "    row=df.iloc[row_index]\n",
        "    row_freq=row['frequency']\n",
        "    freq_Array.append(row_freq)\n",
        "  for i in range (0,len(freq_Array)):\n",
        "    print(freq_Array[i])\n",
        "  return freq_Array\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adf6OqIGDKNH"
      },
      "source": [
        "#Extracting top 3 frequencies\n",
        "def extract_top_freq(freq_Array):\n",
        "  top_3_f=[]\n",
        "  top_3_f=freq_Array\n",
        "  top_3_f.sort(reverse=True)\n",
        "  freq3=[]\n",
        "  freq3=top_3_f[:3]\n",
        "  freq3\n",
        "  return freq3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ezf0R5puqK5"
      },
      "source": [
        "#frequency indexes\n",
        "def freq_index(df,freq3):\n",
        "  tempFreq=[]\n",
        "  index_f=[]\n",
        "  tempFreq=df['frequency'].values\n",
        "  for i in range (0,len(freq3)):\n",
        "    for j in range (0,len(tempFreq)):\n",
        "      if ((int((freq3[i])))==(int((tempFreq[j])))):\n",
        "        index_f.append(j)\n",
        "  final_freq=np.unique(index_f)\n",
        "  final_freq\n",
        "  return final_freq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5DGokx1LWvl"
      },
      "source": [
        "Amplitude"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCOYmBFPKeoS"
      },
      "source": [
        "\n",
        "\n",
        "#Extracting Amplitude of audio\n",
        "def make_df_amp(speech, rate):\n",
        "  length = speech.shape[0] / rate\n",
        "  time = np.linspace(0., length, speech.shape[0])\n",
        "  fifteen_sec_time = np.arange(start=0., stop=length, step=5.0)\n",
        "  print(fifteen_sec_time)\n",
        "  print(len(time), len(fifteen_sec_time))\n",
        "  print(int(len(time)/len(fifteen_sec_time)))\n",
        "  div_val = int(len(time)/len(fifteen_sec_time))\n",
        "\n",
        "  speech = [x*pow(10, 5) for x in speech]\n",
        "  j = 0\n",
        "  amp_array = []\n",
        "  for i in range(0, len(fifteen_sec_time)):\n",
        "    amp_array.append((np.mean(speech[i*div_val:(i+1)*div_val])))\n",
        "\n",
        "  df_amp = pd.DataFrame(columns=['time', 'amplitude'])\n",
        "  df_amp['time'] = fifteen_sec_time\n",
        "  df_amp['amplitude'] = amp_array\n",
        "  print(df_amp)\n",
        "  return df_amp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhvHIOicMoBQ"
      },
      "source": [
        "#Amplitude values corresponding to key words\n",
        "def extract_keywords_amp(df_amp,index_ids):\n",
        "  time_Array=index_ids\n",
        "  amp_Array=[]\n",
        "  for i in range(0,len(time_Array)):\n",
        "    row_index_amp=time_Array[i]\n",
        "    row2=df_amp.iloc[row_index_amp]\n",
        "    row_amp=row2['amplitude']\n",
        "    amp_Array.append(row_amp)\n",
        "  for i in range (0,len(amp_Array)):\n",
        "    print(amp_Array[i])\n",
        "  return amp_Array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRU9OseCI2Ss"
      },
      "source": [
        "#Extracting top 5 amplitude\n",
        "def extract_top_amp(amp_Array):\n",
        "  top_7_amp=[]\n",
        "  top_7_amp=amp_Array\n",
        "  top_7_amp.sort(reverse=True)\n",
        "  amp7=[]\n",
        "  amp7=top_7_amp[:7]\n",
        "  amp7\n",
        "  return amp7"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMo8Bd1Gu49E"
      },
      "source": [
        "#Amplitude indexes\n",
        "def amp_index(df_amp,amp7):\n",
        "  tempAmp=[]\n",
        "  index_a=[]\n",
        "  tempAmp=df_amp['amplitude'].values\n",
        "  for i in range (0,len(amp7)):\n",
        "    for j in range (0,len(tempAmp)):\n",
        "      if ((round((amp7[i]),1))==(round((tempAmp[j]),1))):\n",
        "        index_a.append(j)\n",
        "  index_a\n",
        "  final_amp=np.unique(index_a)\n",
        "  final_amp\n",
        "  return final_amp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEJBJX-V1cz4"
      },
      "source": [
        "def transcribe_amp_freq_regions(final_freq,final_amp,main_transcription):\n",
        "  freq_transcription=[]\n",
        "  for i in range(0,len(final_freq)):\n",
        "    freq_transcription.append(main_transcription[final_freq[i]])\n",
        "  amp_transcription=[]\n",
        "  for i in range(0,len(final_amp)):\n",
        "    amp_transcription.append(main_transcription[final_amp[i]])\n",
        "  print(freq_transcription)\n",
        "  print(amp_transcription)\n",
        "  return freq_transcription, amp_transcription"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJSypCemXwpU"
      },
      "source": [
        "def highlighted_text(freq_transcription,amp_transcription):\n",
        "  with open('finalInference.txt','r') as file:\n",
        "      text = file.read()\n",
        "      text_list = nltk.tokenize.sent_tokenize(text)\n",
        "  highlight_index=[]\n",
        "  for i in range(0,len(freq_transcription)):\n",
        "    scores=[]\n",
        "    for j in range (0,len(text_list)):\n",
        "      scores.append(fuzz.partial_ratio(freq_transcription[i],text_list[j]))\n",
        "    highlight_index.append(scores.index(max(scores)))\n",
        "  for i in range(0,len(amp_transcription)):\n",
        "    scores=[]\n",
        "    for j in range (0,len(text_list)):\n",
        "      scores.append(fuzz.partial_ratio(amp_transcription[i],text_list[j]))\n",
        "    highlight_index.append(scores.index(max(scores)))\n",
        "\n",
        "  highlighted_text=[]\n",
        "\n",
        "  unique_highlight_index=set(highlight_index)\n",
        "  unique_highlight_index=list(unique_highlight_index)\n",
        "  for i in range (0,len(unique_highlight_index)):\n",
        "    highlighted_text.append(text_list[unique_highlight_index[i]])\n",
        "  print(highlighted_text)\n",
        "  return highlighted_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SxhdascqpZ1"
      },
      "source": [
        "def Transcription(ID):\n",
        "  creating_files()\n",
        "  dowloadAudio(ID)\n",
        "  aud_chunks=chunk_on_silence()\n",
        "  wav2vec2(aud_chunks)\n",
        "  Punctuate()\n",
        "  AutoCorrection()\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eq0Ad_KKca0"
      },
      "source": [
        "def Generate_Keywords():\n",
        "  lemmatizedText()\n",
        "  key_terms, keywords_list, topic_word= extract_keywords()\n",
        "  keyword_nouns=extract_nouns(key_terms)\n",
        "  return keyword_nouns, keywords_list, topic_word"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1SVFDy_g5Sf"
      },
      "source": [
        "def Generate_Summary():\n",
        "  summarize_text()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJSg0Xjyg6h4"
      },
      "source": [
        "def Emphasis_Detection(keyword_nouns):\n",
        "  chunks=Chunks_five_sec()\n",
        "  index_ids, main_transcription=find_keywords_in_Audio(keyword_nouns,chunks)\n",
        "  speech,rate=load_audio()\n",
        "  df=make_df_freq(speech,rate)\n",
        "  freq_Array=extract_keywords_freq(df,index_ids)\n",
        "  freq3=extract_top_freq(freq_Array)\n",
        "  final_freq=freq_index(df,freq3)\n",
        "\n",
        "  df_amp=make_df_amp(speech, rate)\n",
        "  amp_Array=extract_keywords_amp(df_amp,index_ids)\n",
        "  amp7=extract_top_amp(amp_Array)\n",
        "  final_amp=amp_index(df_amp,amp7)\n",
        "\n",
        "  freq_transcription,amp_transcription=transcribe_amp_freq_regions(final_freq,final_amp,main_transcription)\n",
        "  \n",
        "  return freq_transcription,amp_transcription"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhIrHiMbig5H"
      },
      "source": [
        "def Highlighted_Transcription(freq_transcription,amp_transcription):\n",
        "  highlighted_trans=highlighted_text(freq_transcription,amp_transcription)\n",
        "  return highlighted_trans"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXhOqxyMKZIF"
      },
      "source": [
        "#Calling Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fipykl_WuYkH"
      },
      "source": [
        "# ID='2xbAiKyTveU'\n",
        "# # ID='rDIlR71omg4'\n",
        "# Transcription(ID)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DETdVmzqutPX"
      },
      "source": [
        "# keyword_nouns, keywords_list, topic_word=Generate_Keywords()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLQUouU6uydb"
      },
      "source": [
        "# Generate_Summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYcziJ58u1uK"
      },
      "source": [
        "# freq_trans,amp_trans=Emphasis_Detection(keyword_nouns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MV3TRCBnu7pt"
      },
      "source": [
        "# highlighted_trans= Highlighted_Transcription(freq_trans,amp_trans)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-REJjirNK35"
      },
      "source": [
        "#Flask Front End"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cA7nNskF5Yri"
      },
      "source": [
        "!pip install flask-ngrok"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbnYVSwd9GUh"
      },
      "source": [
        "from flask_ngrok import run_with_ngrok\n",
        "from flask import Flask, render_template, request, redirect, url_for, make_response\n",
        "\n",
        "app = Flask(__name__, template_folder='drive/MyDrive/FYP/templates', static_folder='drive/MyDrive/FYP/templates/static')\n",
        "run_with_ngrok(app)   #starts ngrok when the app is run \n",
        "\n",
        "##app = Flask(__name__)\n",
        "\n",
        "ytlink = \"\"\n",
        "yt_id = \"\"\n",
        "\n",
        "@app.route(\"/\")\n",
        "def home():\n",
        "  return render_template(\"homepage.html\")\n",
        "\n",
        "@app.route(\"/get-youtube-link\", methods =[\"GET\", \"POST\"])\n",
        "def getlink():\n",
        "  if request.method == \"POST\":\n",
        "    ytlink = request.form.get(\"link\")\n",
        "    list1 = ytlink.split('=')\n",
        "    if (len(list1)==3):\n",
        "      list2 = list1[1].split('&')\n",
        "      yt_id = list2[0]\n",
        "    else:\n",
        "      yt_id = list1[1]\n",
        "\n",
        "    #yt(yt_id)\n",
        "    res = make_response(redirect(url_for('full_transcription')))  \n",
        "    #res = make_response()\n",
        "    res.set_cookie(\"yt_id\", value = yt_id)\n",
        "    creating_files()\n",
        "    return res\n",
        "  return render_template(\"get-youtube-link.html\")\n",
        "\n",
        "@app.route(\"/lecture-notes\", methods = [\"GET\", \"POST\"])\n",
        "def notes():\n",
        "  listofkeywords = []\n",
        "  yt_id = request.cookies.get('yt_id')\n",
        "  ytlink_embed = \"https://www.youtube.com/embed/\"+yt_id\n",
        "  Generate_Summary()\n",
        "  f = open('SummarizedText.txt', 'r')\n",
        "  text = f.read()\n",
        "  t1 = text.split('\\n')\n",
        "  if request.method == \"POST\":\n",
        "    return redirect(url_for('notes_with_keywords'))\n",
        "  return render_template(\"notes-page.html\", listofkeywords = listofkeywords, ytlink_embed = ytlink_embed, display_notes = t1)\n",
        "\n",
        "@app.route(\"/lecture-notes-with-keywords\", methods = [\"GET\", \"POST\"])\n",
        "def notes_with_keywords():\n",
        "  listofkeywords = []\n",
        "  yt_id = request.cookies.get('yt_id')\n",
        "  ytlink_embed = \"https://www.youtube.com/embed/\"+yt_id\n",
        "  f = open('SummarizedText.txt', 'r')\n",
        "  text = f.read()\n",
        "  t1 = text.split('\\n')\n",
        "  listofkeywords, keywords_list, topic_word = Generate_Keywords()\n",
        "  return render_template(\"notes-page-with-keywords.html\", listofkeywords = listofkeywords, ytlink_embed = ytlink_embed, display_notes = t1)\n",
        "\n",
        "@app.route(\"/help\")\n",
        "def help():\n",
        "  return render_template(\"help-page.html\")\n",
        "\n",
        "@app.route(\"/full-transcription\", methods = [\"GET\", \"POST\"])\n",
        "def full_transcription():\n",
        "  listofkeywords = []\n",
        "  lines = []\n",
        "  yt_id = request.cookies.get('yt_id')\n",
        "  try:\n",
        "    f = open('finalInference.txt', \"r\")\n",
        "    lines = f.readline()\n",
        "    f.close()\n",
        "  except IOError:\n",
        "    print(\"No file found\")\n",
        "\n",
        "  if (len(lines) == 0):\n",
        "    Transcription(yt_id)\n",
        "    f = open('finalInference.txt', \"r\")\n",
        "    lines = f.readline()\n",
        "    f.close()\n",
        "\n",
        "  t1 = lines.split(\". \")\n",
        "  t1 = [x+'.' for x in t1]\n",
        "\n",
        "  keyword_nouns, keywords_list, topic_word = Generate_Keywords()\n",
        "  freq_transcription, amp_transcription = Emphasis_Detection(keyword_nouns)\n",
        "\n",
        "  highlights = Highlighted_Transcription(freq_transcription,amp_transcription)\n",
        "\n",
        "  f = open('KeySentences.txt', 'w')\n",
        "  for i in range(0, len(highlights)-1):\n",
        "    f.write(highlights[i]+'\\n')\n",
        "  f.write(highlights[-1])\n",
        "  f.close()\n",
        "\n",
        "  #print(yt_id)\n",
        "  ytlink_embed = \"https://www.youtube.com/embed/\"+yt_id\n",
        "  if request.method == \"POST\":\n",
        "    return redirect(url_for('full_transcription_with_keywords'))\n",
        "  return render_template(\"full-text-transcription.html\", listofkeywords = listofkeywords, ytlink_embed = ytlink_embed, transcription = t1, highlights = highlights)\n",
        "\n",
        "@app.route(\"/full-transcription-with-keywords\", methods = [\"GET\", \"POST\"])\n",
        "def full_transcription_with_keywords():\n",
        "  f = open('finalInference.txt', \"r\")\n",
        "  lines = f.readline()\n",
        "  f.close()\n",
        "  #print(yt_id)\n",
        "  yt_id = request.cookies.get('yt_id')\n",
        "  ytlink_embed = \"https://www.youtube.com/embed/\"+yt_id\n",
        "\n",
        "  f = open('KeySentences.txt', 'r')\n",
        "  highlights = f.read()\n",
        "\n",
        "  highlights = highlights.split('\\n')\n",
        "\n",
        "  t1 = lines.split(\". \")\n",
        "  t1 = [x+'.' for x in t1]\n",
        "\n",
        "  listofkeywords, keywords_list, topic_word = Generate_Keywords()\n",
        "  return render_template(\"full-text-transcription-with-keywords.html\", listofkeywords = listofkeywords, ytlink_embed = ytlink_embed, transcription = t1, highlights = highlights)\n",
        "  #return render_template(\"full-text-transcription.html\", listofkeywords = listofkeywords, ytlink_embed = ytlink_embed, transcription = lines)\n",
        "\n",
        "@app.route(\"/loading\")\n",
        "def loading():\n",
        "  return render_template(\"loading-page.html\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  app.run()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}